{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternating Least-Squares (ALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS is one of many techniques used for constructing recommendation engines. Two fundamental distinctions should be borne in mind: (1) item-based vs. user-based systems, and (2) memory-based vs. model-based systems.\n",
    "\n",
    "For (1), consider two different strategies: (a) I recommend items to you that are similar to other items you've used/bought/read/watched; and (b) I recommend items to you that people similar to you have used/bought/read/watched. The first is the item-based strategy; the second is the user-based strategy. For more see [this Wikipedia article](https://en.wikipedia.org/wiki/Collaborative_filtering) and [this blog post](https://towardsdatascience.com/recommendation-systems-models-and-evaluation-84944a84fb8e). [This post](https://dataconomy.com/2015/03/an-introduction-to-recommendation-engines/) on dataconomy is also useful.\n",
    "\n",
    "The core of (2) is in whether (a) the system uses existing ratings to compute user-user or item-item similarity, or (b) the system uses machine learning techniques to make predictions.\n",
    "\n",
    "ALS is user-based and model-based, as should become clear below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import gauss as gs\n",
    "from random import uniform as uni\n",
    "from random import seed\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we start with a matrix $R$ of users and products, where each cell records the ranking the relevant user gave to the relevant product. Very often we'll be able to record this data as a sparse matrix, because many users will not have ranked many items.\n",
    "\n",
    "\n",
    "ALS recommendation systems are often implemented in Spark architectures because of the appropriateness for distributed computing. ALS systems often involve very large datasets (consider how much data the recommendation engine for NETFLIX must have, for example!), and it is often useful to store them as sparse matrices, which Spark's ML library can handle. In fact, Spark's mllib even includes a \"Rating\" datatype!\n",
    "\n",
    "Imagine factoring this matrix into a user matrix and an item matrix: $R = PQ^T$. Then we could predict a user's ranking of a particular item simply by calculating $p^Tq$, the dot-product of a row of $P$ and a column of $Q^T$. Why? The user vector records the user's preferences with respect to certain latent features, while the item vector records how the item ranks with respect to those preferences.\n",
    "\n",
    "We could therefore calculate *all* predictions, i.e. fill in the gaps in $R$, by solving for P and Q.\n",
    "\n",
    "But how can we solve for two variables at once? Well, we can't. But here's what we can do:\n",
    "\n",
    "Make guesses of the values for P and Q. Then hold the values of one *constant* so that we can optimize for the values of the other!\n",
    "\n",
    "Basically this converts our problem into a familiar *least-squares* problem. See [this page](https://textbooks.math.gatech.edu/ila/least-squares.html) and [this page](https://datasciencemadesimpler.wordpress.com/tag/alternating-least-squares/) for more details, but here's the basic idea:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have an equation $Ax = b$ for *non-square* $A$, then we have:\n",
    "\n",
    "$A^TAx = A^Tb$ <br/>\n",
    "Thus: <br/>\n",
    "$x = (A^TA)^{-1}A^Tb$\n",
    "\n",
    "This $(A^TA)^{-1}A^T$ **is the pseudo-inverse of** $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "A = np.random.rand(5, 5)\n",
    "b = np.random.rand(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(A.T.dot(A)).dot(A.T).dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.pinv(A).dot(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"When we talk about collaborative filtering for recommender systems we want to solve the problem of our original matrix having millions of different dimensions, but our 'tastes' not being nearly as complex. Even if iâ€™ve \\[sic\\] viewed hundreds of items they might just express a couple of different tastes. Here we can actually use matrix factorization to mathematically reduce the dimensionality of our original 'all users by all items' matrix into something much smaller that represents 'all items by some taste dimensions' and 'all users by some taste dimensions'. These dimensions are called ***latent or hidden features*** and we learn them from our data\" ([Medium article: \"ALS Implicit Collaborative Filtering\"](https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If P = users and Q = items, then we want to approximate R = PQ^T\n",
    "# Let's generate R.\n",
    "\n",
    "seed(42)\n",
    "ratings = []\n",
    "for _ in range(100):\n",
    "    user = []\n",
    "    for _ in range(100):\n",
    "        user.append(int(uni(1, 6)))\n",
    "    ratings.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "\n",
    "for _ in range(100):\n",
    "    user = []\n",
    "    for _ in range(20):\n",
    "        user.append(gs(0, 2 / np.sqrt(3)))\n",
    "    users.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "\n",
    "for _ in range(100):\n",
    "    item = []\n",
    "    for _ in range(20):\n",
    "        item.append(gs(0, 2 / np.sqrt(3)))\n",
    "    items.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_arr = np.asarray(ratings)\n",
    "users_arr = np.asarray(users)\n",
    "items_arr = np.asarray(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = users_arr.dot(items_arr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = (ratings_arr - guess)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users: m x n (m users)\n",
    "# Items: r x n (r items)\n",
    "# Ratings: m x r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als(ratings, users, items, reps=10):\n",
    "    \n",
    "    ratings_cols = ratings.T\n",
    "    for _ in range(reps):\n",
    "        new_users = []\n",
    "        for i in range(len(ratings)):\n",
    "            user = np.linalg.pinv(items).dot(ratings[i])\n",
    "            new_users.append(user)\n",
    "        new_users = np.asarray(new_users)\n",
    "        \n",
    "        new_items = []\n",
    "        for i in range(len(ratings)):\n",
    "            item = np.linalg.pinv(new_users).dot(ratings_cols[i])\n",
    "            new_items.append(item)\n",
    "        new_items = np.asarray(new_items)\n",
    "        \n",
    "        guess = new_users.dot(new_items.T)\n",
    "        err = (ratings - guess)**2\n",
    "        print(np.sum(err))\n",
    "        \n",
    "        items = new_items\n",
    "        \n",
    "    return new_users, new_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_u, new_i = als(ratings_arr, users_arr, items_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
